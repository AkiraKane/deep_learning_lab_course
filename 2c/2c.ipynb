{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNNs on MNIST\n",
    "In the third part of the exercise we will now apply CNNs to MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at the neural network code I placed into the nn package in this repository. It should look familiar as it is mainly the code you used in the last exercise. One thing that I added is a prototyped implementation of convolution and pooling. You will find these in nn/conv/layers.py.\n",
    "\n",
    "After you have completed exercises 2 a) and 2 b) you should go into that file, and implement the missing pieces, which will essentially be the conv and pool functions you have already written as well as their backward pass (which might be a bit more tricky). \n",
    "\n",
    "Once you implemented those, come back here and make sure the following example works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let us do gradient checking using your conv and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = (1, 1, 28, 28)\n",
    "n_labels = 6\n",
    "layers = [nn.InputLayer(input_shape)]\n",
    "\n",
    "layers.append(nn.Conv(\n",
    "                layers[-1],\n",
    "                n_feats=2,\n",
    "                filter_shape=(3,3),\n",
    "                init_stddev=0.01,\n",
    "                activation_fun=nn.Activation('relu'),\n",
    "))\n",
    "layers.append(nn.Pool(layers[-1]))\n",
    "layers.append(nn.Flatten(layers[-1]))\n",
    "layers.append(nn.FullyConnectedLayer(\n",
    "                layers[-1],\n",
    "                num_units=6,\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=None\n",
    "))\n",
    "layers.append(nn.LinearOutput(layers[-1]))\n",
    "net = nn.NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create random data\n",
    "X = np.random.normal(size=input_shape)\n",
    "Y = np.zeros((input_shape[0], n_labels))\n",
    "for i in range(Y.shape[0]):\n",
    "    idx = np.random.randint(n_labels)\n",
    "    Y[i, idx] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform gradient checking, this should go through if you implemented everything correctly!\n",
    "net.check_gradients(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on mnist\n",
    "Finally, figure out a reasonable network architecture and train it on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# you can load the mnist data as \n",
    "data = nn.data.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import nn\n",
    "import time\n",
    "# you can load the mnist data as [(train_x, train_y), (valid_x, valid_y), (test_x, test_y)]\n",
    "data = nn.data.mnist()\n",
    "X_train = data[0][0]\n",
    "y_train = data[0][1]\n",
    "\n",
    "# Downsample training data to make it a bit faster for testing this code\n",
    "n_train_samples = 10000\n",
    "train_idxs = np.random.permutation(X_train.shape[0])[:n_train_samples]\n",
    "X_train = X_train[train_idxs]\n",
    "y_train = y_train[train_idxs]\n",
    "\n",
    "n_valid_samples = 500\n",
    "X_valid = data[1][0]\n",
    "Y_valid = data[1][1]\n",
    "valid_idxs = np.random.permutation(X_valid.shape[0])[:n_valid_samples]\n",
    "X_valid = X_valid[valid_idxs]\n",
    "Y_valid = Y_valid[valid_idxs]\n",
    "\n",
    "n_test_samples = 500\n",
    "X_test = data[2][0]\n",
    "Y_test = data[2][1]\n",
    "test_idxs = np.random.permutation(X_test.shape[0])[:n_test_samples]\n",
    "X_test = X_test[test_idxs]\n",
    "Y_test = Y_test[test_idxs]\n",
    "\n",
    "input_shape = (None, 1, 28, 28)\n",
    "layers = [nn.InputLayer(input_shape)]\n",
    "layers.append(nn.Conv(\n",
    "                layers[-1],\n",
    "                n_feats=2,\n",
    "                filter_shape=(3,3),\n",
    "                init_stddev=0.01,\n",
    "                activation_fun=nn.layers.Activation('relu')))\n",
    "layers.append(nn.Flatten(layers[-1]))\n",
    "layers.append(nn.FullyConnectedLayer(\n",
    "                layers[-1],\n",
    "                num_units=10,\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=nn.layers.Activation('relu')))\n",
    "layers.append(nn.SoftmaxOutput(layers[-1]))\n",
    "net = nn.NeuralNetwork(layers)\n",
    "\n",
    "start_train_time = time.time()\n",
    "\n",
    "train_errors, valid_errors = net.train(X_train, y_train, Xvalid=X_valid, Yvalid=Y_valid, learning_rate=0.1, max_epochs=15, batch_size=100, y_one_hot=True)\n",
    "end_train_time = time.time()\n",
    "\n",
    "print(\"Training errors: \\n\" + str(train_errors))\n",
    "print(\"Validation errors: \\n\" + str(valid_errors))\n",
    "\n",
    "test_error = net.classification_error(X_test, Y_test)\n",
    "print(\"Test error: {:.4f}\".format(test_error))\n",
    "f = open(\"output.txt\", \"w\")\n",
    "f.write(\"Training errors: \\n\" + str(train_errors) + \"\\n\")\n",
    "f.write(\"Validation errors: \\n\" + str(valid_errors) + \"\\n\")\n",
    "f.write(\"Test error: {:.4f}\".format(test_error) + \"\\n\")\n",
    "f.write(\"Time: {:.2f}\".format(end_train_time - start_train_time))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
