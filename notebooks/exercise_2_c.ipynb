{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNNs on MNIST\n",
    "In the third part of the exercise we will now apply CNNs to MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at the neural network code I placed into the nn package in this repository. It should look familiar as it is mainly the code you used in the last exercise. One thing that I added is a prototyped implementation of convolution and pooling. You will find these in nn/conv/layers.py.\n",
    "\n",
    "After you have completed exercises 2 a) and 2 b) you should go into that file, and implement the missing pieces, which will essentially be the conv and pool functions you have already written as well as their backward pass (which might be a bit more tricky). \n",
    "\n",
    "Once you implemented those, come back here and make sure the following example works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, let us do gradient checking using your conv and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = (5, 1, 28, 28)\n",
    "n_labels = 6\n",
    "layers = [nn.InputLayer(input_shape)]\n",
    "\n",
    "layers.append(nn.Conv(\n",
    "                layers[-1],\n",
    "                n_feats=2,\n",
    "                filter_shape=(3,3),\n",
    "                init_stddev=0.01,\n",
    "                activation_fun=nn.Activation('relu'),\n",
    "))\n",
    "layers.append(nn.Pool(layers[-1]))\n",
    "layers.append(nn.Flatten(layers[-1]))\n",
    "layers.append(nn.FullyConnectedLayer(\n",
    "                layers[-1],\n",
    "                num_units=6,\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=None\n",
    "))\n",
    "layers.append(nn.SoftmaxOutput(layers[-1]))\n",
    "net = nn.NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create random data\n",
    "X = np.random.normal(size=input_shape)\n",
    "Y = np.zeros((input_shape[0], n_labels))\n",
    "for i in range(Y.shape[0]):\n",
    "    idx = np.random.randint(n_labels)\n",
    "    Y[i, idx] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking gradient for layer 1\n",
      "diff 1.01e-08\n",
      "diff 2.13e-08\n",
      "checking gradient for layer 4\n",
      "diff 1.29e-08\n",
      "diff 9.08e-09\n"
     ]
    }
   ],
   "source": [
    "# perform gradient checking, this should go through if you implemented everything correctly!\n",
    "net.check_gradients(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on mnist\n",
    "Finally, figure out a reasonable network architecture and train it on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... done loading data\n"
     ]
    }
   ],
   "source": [
    "# you can load the mnist data as \n",
    "data = nn.data.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a larger conv net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (100, 1, 28, 28)\n",
    "n_labels = 10\n",
    "layers = [nn.InputLayer(input_shape)]\n",
    "\n",
    "layers.append(nn.Conv(\n",
    "                layers[-1],\n",
    "                n_feats=32,\n",
    "                filter_shape=(5,5),\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=nn.Activation('relu'),\n",
    "))\n",
    "layers.append(nn.Pool(layers[-1]))\n",
    "layers.append(nn.Conv(\n",
    "                layers[-1],\n",
    "                n_feats=32,\n",
    "                filter_shape=(5,5),\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=nn.Activation('relu'),\n",
    "))\n",
    "layers.append(nn.Pool(layers[-1]))\n",
    "layers.append(nn.Flatten(layers[-1]))\n",
    "layers.append(nn.FullyConnectedLayer(\n",
    "                layers[-1],\n",
    "                num_units=128,\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=nn.Activation('relu')\n",
    "))\n",
    "layers.append(nn.FullyConnectedLayer(\n",
    "                layers[-1],\n",
    "                num_units=10,\n",
    "                init_stddev=0.1,\n",
    "                activation_fun=None\n",
    "))\n",
    "layers.append(nn.SoftmaxOutput(layers[-1]))\n",
    "net = nn.NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... done loading data\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "Dtrain, Dval, Dtest = nn.mnist()\n",
    "X_train, y_train = Dtrain\n",
    "# Downsample training data to make it a bit faster for testing this code\n",
    "n_train_samples = 10000\n",
    "train_idxs = np.random.permutation(X_train.shape[0])[:n_train_samples]\n",
    "X_train = np.asarray(X_train[train_idxs], dtype=np.float)\n",
    "y_train = y_train[train_idxs]\n",
    "# extract validation data\n",
    "Xvalid, Yvalid = Dval\n",
    "Xvalid = np.asarray(Xvalid, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10000, 1, 28, 28)\n",
      "y_train shape: (10000,)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(np.shape(X_train)))\n",
    "print(\"y_train shape: {}\".format(np.shape(y_train)))\n",
    "print(X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... starting training\n",
      "epoch    0, loss 0.6551, train error 0.0603\n",
      "\t\t\t valid error 0.0637\n",
      "epoch    1, loss 0.1738\n",
      "epoch    2, loss 0.1164\n",
      "epoch    3, loss 0.0876\n",
      "epoch    4, loss 0.0680\n",
      "epoch    5, loss 0.0536, train error 0.0140\n",
      "\t\t\t valid error 0.0276\n",
      "epoch    6, loss 0.0421\n",
      "epoch    7, loss 0.0327\n",
      "epoch    8, loss 0.0250\n",
      "epoch    9, loss 0.0193\n",
      "epoch   10, loss 0.0148, train error 0.0023\n",
      "\t\t\t valid error 0.0226\n",
      "epoch   11, loss 0.0112\n",
      "epoch   12, loss 0.0085\n",
      "epoch   13, loss 0.0067\n",
      "epoch   14, loss 0.0053\n",
      "epoch   15, loss 0.0043, train error 0.0002\n",
      "\t\t\t valid error 0.0215\n",
      "epoch   16, loss 0.0036\n",
      "epoch   17, loss 0.0030\n",
      "epoch   18, loss 0.0026\n",
      "epoch   19, loss 0.0023\n",
      "epoch   20, loss 0.0020, train error 0.0000\n",
      "\t\t\t valid error 0.0213\n",
      "Duration: 1362.4s\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "import time\n",
    "t0 = time.time()\n",
    "net.train(X_train, y_train, Xvalid=Xvalid, Yvalid=Yvalid, learning_rate=0.1, \n",
    "        max_epochs=20, batch_size=100, y_one_hot=True, log_every=5)\n",
    "t1 = time.time()\n",
    "print('Duration: {:.1f}s'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
